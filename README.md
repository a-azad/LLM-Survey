# My Notes

| File | Content |
| --- | --- |
| [1986-2017.md](1986-2017.md) | History of things until the first Transformer |
| [2017-2020.md](2017-2020.md) | Transformer upto GPT3 |
| [metrics.md](metrics.md) | Common metrics in model evaluation |
| [definition.md](definitions.md) | Multi-task, Curriculum and Meta Learning  |
| [survey_01.md](survey_01.md) | Notes on the paper: "A Survey of Large Language Models" |


# Resources

- **2021**
    - [On the Opportunities and Risks of Foundation Models](https://crfm.stanford.edu/report.html) (~200p report)
- **2023**
    - [A Comprehensive Survey on Pretrained Foundation Models](https://arxiv.org/abs/2302.09419)
    - [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
        - [github](https://github.com/RUCAIBox/LLMSurvey)
    - [Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond](https://arxiv.org/abs/2304.13712)
        - [github](https://github.com/Mooler0410/LLMsPracticalGuide)
